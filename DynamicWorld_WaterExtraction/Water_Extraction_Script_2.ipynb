{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5pu20JPbp1p"
      },
      "source": [
        "### Set Up Packages and Authorize Access to GEE and Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luUB_vjtCFqd",
        "outputId": "180940fc-9b62-4757-8c83-921ba7ef166b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully imported ee\n",
            "Successfully imported itertools\n",
            "jenkspy is not installed. Attempting to install it...\n",
            "Successfully imported jenkspy\n",
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=lgu72LFLsj_iIm6MjFe9Zt2betvHamoRyImJXCeXuOU&tc=ceXMcK1fJVgg-BHz-gy4QbVvLq4o-as_5wjSXcSSjYc&cc=obFknfnn0KVTYi1mPmeJz2gIckZt1U5R4ODZ6gjyb2o\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AfJohXno4n2lCTFo7rTv1i83q4cURVG0XT0aUPovWLg70x7k6GC95suQvTQ\n",
            "\n",
            "Successfully saved authorization token.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import subprocess\n",
        "\n",
        "# The list of libraries required\n",
        "libraries = [\"ee\", \"itertools\", \"jenkspy\"]\n",
        "\n",
        "# Automatically import/install the libraries\n",
        "for i in libraries:\n",
        "    try:\n",
        "        library = importlib.import_module(i)\n",
        "        print(f\"Successfully imported {i}\")\n",
        "    except ImportError:\n",
        "        print(f\"{i} is not installed. Attempting to install it...\")\n",
        "        subprocess.check_call([\"pip\", \"install\", i])\n",
        "\n",
        "        try:\n",
        "            library = importlib.import_module(i)\n",
        "            print(f\"Successfully imported {i}\")\n",
        "        except ImportError:\n",
        "            print(f\"Failed to install and import {i}. Please install it manually.\")\n",
        "\n",
        "# Initialize GEE's Python API\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "# Authorize access to Google Drive (for exporting data)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGkQQ63FzNuE"
      },
      "source": [
        "### Specify the GRES ID of the Reservoir(s) to be processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXwOIwi7zUtq"
      },
      "outputs": [],
      "source": [
        "# Enter the list of id from the GRES_Polys that you want to process, it can take a single or multiple ids\n",
        "GRES_ID = [127,34]\n",
        "\n",
        "# Where to export the raster on Google Drive?\n",
        "RasterFolder = \"GEE_Raster\"\n",
        "\n",
        "# Where to export the water polygons on Google Drive?\n",
        "PolyFolder = \"GEE_Polygon\"\n",
        "\n",
        "# Where is your polygon data source?\n",
        "GRes_polys = ee.FeatureCollection('projects/ee-climatechangehydrology1/assets/GRes_Polys')\n",
        "\n",
        "# What is path of your GEE Asset?\n",
        "Asset_Folder_Path= 'projects/ee-climatechangehydrology/assets/GRes_ProbabilityRaster/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoW3fLnqHak7"
      },
      "source": [
        "### Batch Process Multiple Reservoirs\n",
        "*   This section of the module uses a \"for\" loop that iteratively select each id in the list, use it as a string to query data and submit tasks on the server;\n",
        "Unlike using the .map() function, this iteration only applied to the python\n",
        "list locally to allow the functions to be used repeatly. This avoid\n",
        "encountering errors such as \"User Memory Exceed\" or \"Computation Timeout\"\n",
        "due to the GEE's \"Per-request Memory Footprint\", which is that limited RAM\n",
        "is assigned for each user for in-memeory data processing.\n",
        "*   For more info about GEE's computation limits,\n",
        "    see: https://developers.google.com/earth-engine/guides/usage\n",
        "\n",
        "*   A preview on some of the aggregation-based parameters:\n",
        "\n",
        "  \"tileScale\"(0-16): setting a larger tilescale value means the image is dividied\n",
        "  into smaller chunks/tiles for parallel processing, this will slow down the\n",
        "  computation because there are more tiles need to be aggregated at the end.\n",
        "  However, it will allow the operations to succeed since a large task is being\n",
        "  splited into many smaller tasks. For small reservoirs, consider adjusting\n",
        "  the tileScale to 8 or 10 to speed up processing.\n",
        "\n",
        "  \"bestEffort = True\": scale/resolution of the image may be reduced to allows\n",
        "  the computation to succeed at the given value of maxPixels; It's necessary for\n",
        "  large reservoir, but the result of this may excludes some water edges.\n",
        "  (similar to using \"simplify polygon\" in ArcGIS Pro)\n",
        "\n",
        "  \"eightConnected = True\": it means a pixel at the center of the 3x3 grid is\n",
        "  considered connected to all eight surrounding pixels, even the diagonals.\n",
        "  If false, it uses a four-connected system, only those pixels with four-\n",
        "  connected neighbourds (top, bottom, left, right) are converted into a polygon.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "086GdOOXHh4e",
        "outputId": "261d62e4-608e-4942-dd0e-b9dd0a1918d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation Successful on GRES_ID: 127.\n",
            "Operation Successful on GRES_ID: 34.\n",
            "Operation is completed. Check your export tasks on GEE's Task Manager\n"
          ]
        }
      ],
      "source": [
        "# re-state the import statements\n",
        "# These libraries are needed for \"client-side\" operations\n",
        "import jenkspy\n",
        "from itertools import repeat\n",
        "\n",
        "for id in GRES_ID:\n",
        "  try:\n",
        "    # Get the pre-processed probability raster\n",
        "    ProbabilityRaster = ee.Image(Asset_Folder_Path + 'GRES_' + str(id))\n",
        "    # Get some attribute data from \"GRES_Polys\" to be copied to the results\n",
        "    feature = GRes_polys.filter(ee.Filter.eq('GRES_ID', id))\n",
        "    # Get name of the reservoir\n",
        "    res_name = feature.aggregate_array(\"DAM_NAME\").getString(0).getInfo()\n",
        "    # Get id of the reservoir in the \"GRAND\" Database\n",
        "    grand_id = feature.aggregate_array(\"GRAND_ID\").getNumber(0).getInfo()\n",
        "    # Get id of the reservoir in the \"GeoDAR v1.3\" database\n",
        "    geodar_id = feature.aggregate_array(\"ID_GRDv13\").getNumber(0).getInfo()\n",
        "    # Get province name (\"administration unit\")\n",
        "    province = feature.aggregate_array(\"ADMIN_UNIT\").getString(0).getInfo()\n",
        "    # Normalize the range of probability values into a 0-1 scale\n",
        "    Image_MinMax = ProbabilityRaster.reduceRegion(\n",
        "        reducer=ee.Reducer.minMax(),\n",
        "        geometry= ProbabilityRaster.geometry(),\n",
        "        scale=10,\n",
        "        maxPixels= 1e13,\n",
        "        tileScale = 16\n",
        "    )\n",
        "    min = Image_MinMax.getNumber('probability_min')\n",
        "    max = Image_MinMax.getNumber('probability_max')\n",
        "    norm_prob_ras = ProbabilityRaster.select('probability').unitScale(min,max)\n",
        "\n",
        "    \"\"\"\n",
        "    *** The following section performs a data classifcation ***\n",
        "    1. Compute a Histogram to store raster statistics in a list, with\n",
        "        ee.Reducer.fixedHistogram (fixed width, 100 buckets, 0.01 width),\n",
        "        which is a server-side operation.\n",
        "\n",
        "        Direct conversion from ee.Image to ee.Array is not possible at this\n",
        "        given scale and amount of operations; However, we already computed\n",
        "        a min/max stretched ee.Image and we know that min = 0 and max =1.\n",
        "\n",
        "    2. Create a list of synthetic data values derived from the histogram to\n",
        "    replicate the original data distribution of the raster.\n",
        "\n",
        "    3. Classify the synthetic data into three classes based on their\n",
        "      \"natural breaks\" using the \"Fisher-Jenks Algorithm\" from jenkspy.\n",
        "      (This is a client-side operation that consumes local RAM, the script\n",
        "      may takes longer than usual at this step, especially for large\n",
        "      reservoirs).\n",
        "\n",
        "    3. Categorize the synthetic data into three classes using the\n",
        "    \"Fisher-Jenks Algorithm\" from jenkspy, based on their optimal\n",
        "    \"natural breaks.\"\n",
        "\n",
        "      This operation would be processed on the client side using Google Collab's\n",
        "      VRAM as a way to avoid overloading the gee server; It can take longer than\n",
        "      usual for extremely large reservoirs.\n",
        "\n",
        "    \"\"\"\n",
        "    ## ee.Reducer.fixedHistogram is a server-side operation;\n",
        "    ## To avoid computation timeout, we can set maxPixels = 1e13 and\n",
        "    ## tileScale = 16.\n",
        "    bucket_count = ee.Array(norm_prob_ras.reduceRegion(\n",
        "        reducer=ee.Reducer.fixedHistogram(min=0, max=1, steps=100),\n",
        "        geometry=ProbabilityRaster.geometry(),\n",
        "        scale=10,\n",
        "        maxPixels=1e13,\n",
        "        tileScale=16\n",
        "    ).get('probability'))\n",
        "\n",
        "\n",
        "    # The output is a 1x2 array;\n",
        "    # Reshape the array into a 1x1 array, and then convert it into a ee.List;\n",
        "    # The ee.list would contain 200 elements in the following order\n",
        "    # (bucket, count, bucket, count, ....)\n",
        "    bucket_count = bucket_count.reshape([-1]).toList().flatten()\n",
        "\n",
        "    # Slice and separate the values into two lists: bucket, count;\n",
        "    # For bucket, we need to round the values to the nearest two decimals;\n",
        "    # For count, we need to round the values into the nearest whole number;\n",
        "    # Use .getInfo() to retrieve the data from the server as python lists;\n",
        "    # The python list would allow us to use normal python packages;\n",
        "\n",
        "    bucket = bucket_count.slice(0,201,2)\n",
        "    bucket = bucket.map(\n",
        "        lambda number: ee.Number(number).multiply(100).round().divide(100)\n",
        "    )\n",
        "    bucket = bucket.getInfo()\n",
        "\n",
        "    count = bucket_count.slice(1,201,2)\n",
        "    count = count.map(lambda number: ee.Number(number).round())\n",
        "    count = count.getInfo()\n",
        "\n",
        "\n",
        "    # Before we generate a list of synthetic data points,\n",
        "    # we can avoid unnecessary computation by reducing the the number of\n",
        "    # repeated values porportionally.The break values won't be affected in\n",
        "    # this scenario.\n",
        "    min_count = sorted(count)[0]\n",
        "    if min_count >100:\n",
        "      count = [round(x / 100) for x in count]\n",
        "    elif min_count >10:\n",
        "      count = [round(x / 10) for x in count]\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    # After checking for redundant values,\n",
        "    # we can generate a list of synthetic data points and do a 3-class\n",
        "    # natural breaks classifcation to identify\n",
        "    # [non-water, seasonal water, permanent water].\n",
        "    bucket_count = list(zip(bucket,count))\n",
        "    syn_data = [bucket for bucket, count in bucket_count for i in repeat(None, int(count))]\n",
        "    natural_breaks = jenkspy.jenks_breaks(syn_data, n_classes=3)\n",
        "\n",
        "    # example: natural_breaks = [0.0, 0.33, 0.66, 1.0 ]\n",
        "    # index 0 to 1 is non-water, 1-2 is seasonal water, 2-3 is permanent water\n",
        "    max_water = norm_prob_ras.gt(natural_breaks[1]).selfMask()\n",
        "    min_water = norm_prob_ras.gt(natural_breaks[2]).selfMask()\n",
        "\n",
        "    # Convert the new layer into vectors\n",
        "    conversion_params = {\n",
        "        'geometryType': 'polygon',\n",
        "        'geometry': ProbabilityRaster.geometry(),\n",
        "        'scale': 10,\n",
        "        'eightConnected': True,\n",
        "        'labelProperty': 'GRES_ID',\n",
        "        'bestEffort': True,\n",
        "        'tileScale': 16\n",
        "    }\n",
        "\n",
        "    def set_properties(feature):\n",
        "      return feature.set({\n",
        "            'GRES_ID': int(id),\n",
        "            'NAME': str(res_name),\n",
        "            'BREAK': str(natural_breaks),\n",
        "            'GRAND_ID': int(grand_id),\n",
        "            'ID_GRDv13': int(geodar_id),\n",
        "            'PROV': str(province)\n",
        "      })\n",
        "\n",
        "    # The results are multi-part polygons,\n",
        "    # with a default projection EPSG:4326.\n",
        "    max_water_poly = max_water.reduceToVectors(**conversion_params)\n",
        "    min_water_poly = min_water.reduceToVectors(**conversion_params)\n",
        "\n",
        "    max_water_poly = max_water_poly.map(set_properties)\n",
        "    min_water_poly = min_water_poly.map(set_properties)\n",
        "\n",
        "    # Remove those vectors with pixel counts <=1\n",
        "    max_water_poly = max_water_poly.filter(\"count != 1\").filter(\"count != 0\")\n",
        "    min_water_poly = min_water_poly.filter(\"count != 1\").filter(\"count != 0\")\n",
        "\n",
        "    # Set Export Tasks\n",
        "    Export_ProbailityRaster = ee.batch.Export.image.toDrive(\n",
        "        image = norm_prob_ras,\n",
        "        region = norm_prob_ras.geometry(),\n",
        "        folder = RasterFolder,\n",
        "        description = 'GRES_' + str(id) + '_GeoTIFF',\n",
        "        fileFormat = 'GeoTIFF',\n",
        "        scale = 10,\n",
        "        maxPixels = 1e13\n",
        "    )\n",
        "\n",
        "    Export_MaxWaterPolys = ee.batch.Export.table.toDrive(\n",
        "        collection=max_water_poly,\n",
        "        folder=PolyFolder,\n",
        "        description='GRES_' + str(id) + '_MaxWater',\n",
        "        fileFormat='SHP'\n",
        "    )\n",
        "\n",
        "    Export_MinWaterPolys = ee.batch.Export.table.toDrive(\n",
        "        collection=min_water_poly,\n",
        "        folder=PolyFolder,\n",
        "        description='GRES_' + str(id) + '_MinWater',\n",
        "        fileFormat='SHP'\n",
        "    )\n",
        "\n",
        "    # Initiate the export tasks;\n",
        "    # Comment out the task if not required;\n",
        "    Export_ProbailityRaster.start()\n",
        "    Export_MaxWaterPolys.start()\n",
        "    Export_MinWaterPolys.start()\n",
        "    print(f\"Operation Successful on GRES_ID: {id}.\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Operation Failed on GRES_ID: {id}. Please check your input.\")\n",
        "\n",
        "# Print when execution completes\n",
        "print(\"Operation is completed. Check your export tasks on GEE's Task Manager\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
